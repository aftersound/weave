# Deliver Data Insights to Product Experience at Scale

This article is about solution that delivers data insights to product experience, the focuses are A and B and C in 
diagram below.

![](diagrams/INSIGHT-DELIVERY-IN-THE-BIG-PICTURE.png)

## The gap

If you work in data area, the left part of the diagram above, Data Insight Mining, might look familiar to you. If you 
work on Product Experience, the right part should be obvious.  

Questions is when product experiences need the data insights generated by data processing workloads, how to make this 
happen? Can product experiences directly use data insights from data processing pipeline?
 
More often than not, such data insights can not be directly used by product experiences. Reasons are

1. product experiences often want different views of the same data insights
2. product experiences often have different access patterns
3. product experiences often have strict requirement on latency

So, there is still some gap between generated data insights and product experiences. To cover it, significant amount of 
engineering time/effort is needed. 


## The common approach

To fill the gap, 

- A. certain type(s) of databases is selected based on access pattern/latency requirement, some data loader is 
created to load data insights into selected database

- B. some service is built, which reads data from database

- C. service does some lightweight transformation to produce views preferred by product experiences

## The Practices and associated issues

The approach is sound and clear. But there are many issues when time comes to implementations and practices, and the 
dynamics between data teams and product experience teams often plays a big part. Among all the issues, the biggest one
 is **purpose-built solution**.

On one hand, product experience teams' focal point is product, which is usually domain/experience specific. If it's 
one product experience team to build a solution or that product experience team has a big say in the solution, it's 
often for that specific product experience. Data model early optimization might happens in data insights as output of 
data processing, sometimes even sneaks into data processing workload. Service interface is often tailored for that 
experience. The possibility that the data insight might have a wider spectrum of use cases is not in the consideration 
of product experience teams. When a new use case of the same data insight arises in different product domain, the built 
solution doesn't fit.

On the other hand, data team's focus is to mine data insights by applying data science and engineering techniques and 
operating data processing workload and pipelines, etc. The work is often data set specific, also very detail-oriented. 
Such work has too much of their attention, such work shapes their way of approaching problems. When comes to 
build something to deliver data insight to product experience, data team also tends to create purpose-build solution 
for each use case.

The biggest problems of purpose-built solutions include 

- hard to change
- lack of engineering consistency
- impede engineering efficiency and effectiveness
- limit the value of data insight

## The Weave Solution

Data teams should be encouraged to look at data insight with holistic and end-to-end view, to expand/extends their 
boundary closer to product experiences.

When there is a great solution for delivering data insights to product experience, which 

- enforces engineering consistency
- is functionally rich
- is easy to build and operate data loading jobs and data services

For data teams, they could remain their focuses on mining data insights, maximize the value of data insights by 
supporting as many use-cases as possible from product experiences without spending too much effort in building and 
operating insight delivery data loaders and data services.

For product experience teams, they could still get the data insights, but in faster paces, while still enjoy data view,
 access patterns, latency which are specific to product experience in specific domain.
 
Weave is set to become such a solution to scale data team and product experience team by boosting engineering efficiency
and effectiveness with regard to insight delivery.

- it fully adopts and embraces a well-thought 
[CAP component structure](https://aftersound.github.io/weave/control-actor-product-component-structure), which enforces
great engineering consistency and makes extensions possible and simple.

- its batch framework, built on top of CAP, provides the capability of declaratively creating and operating data 
loaders at runtime.

- its [service framework](https://aftersound.github.io/weave/micro-service-virtualization-over-cap-closer-look), also 
built on top of CAP, offers building and operating virtualized data services through service metadata.

## About Weave

[Weave](https://github.com/aftersound/weave) is a Java-based declarative service/batch framework targeting data area. 

It's open source and still in early phase. All contributions are welcome.





 
 